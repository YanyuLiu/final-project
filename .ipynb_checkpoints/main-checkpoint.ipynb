{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy.random as nrd\n",
    "from sklearn.cluster import KMeans\n",
    "from kmeans import *\n",
    "%matplotlib inline\n",
    "%precision 4\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GAUSSMIXTURE, which is synthetic. To generate it, I first sample k=(3,4,5) centers from a 3-dimensional Gaussian distribution with mean 0 and variance 5$I_3$. Then add points from Gaussian distributions of unit variance around centers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#first only generate k=5\n",
    "\n",
    "nrd.seed(1234)\n",
    "k = 20\n",
    "centers = nrd.multivariate_normal([0]*10,5*np.identity(10),k)\n",
    "data = [nrd.multivariate_normal(center, np.identity(10),100) for center in centers]\n",
    "data = np.vstack(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def Cost(C, Y):\n",
    "    \"\"\"C is a subset of the dataset, Y can be a point or a subset\"\"\"\n",
    "    if  len(Y.shape)==1 or Y.shape[0]==1:\n",
    "        #Y is a point\n",
    "        MinIndex = np.argmin(np.sum((Y-C)**2,axis=1))\n",
    "        return np.sum((Y-C[MinIndex,])**2)\n",
    "    else:\n",
    "        return np.sum([Cost(C,Y_i) for Y_i in Y])\n",
    "\n",
    "def weight(C, data):\n",
    "    \"\"\"C is the centroid set and data is the target data set\"\"\"\n",
    "    if len(C.shape)==1 or C.shape[0]==1:\n",
    "        #C only have one point\n",
    "        if len(data.shape)==1 or data.shape[0]==1:\n",
    "            return np.array([1])\n",
    "        else:\n",
    "            return np.array([len(data)])\n",
    "    else:\n",
    "        Cost_matrix = np.array([np.sum((c-x)**2) for c in C\n",
    "                                             for x in data]).reshape(len(C),len(data))\n",
    "        Index_min = list(np.argmin(Cost_matrix,axis=0))\n",
    "        return np.array([Index_min.count(i) for i in range(len(C))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-means||"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def kmeanspar(k,l,r,data):\n",
    "    \"\"\"k is the number of centers, l is the expected number of intermediate points\n",
    "    in each iteration, r is the number of iterations, data is the target data set\"\"\"\n",
    "    #l*r should be larger than k in case k-means|| select too few points\n",
    "    if l*r < k:\n",
    "        raise ValueError('r or l must be bigger, ')\n",
    "    #if k is too large\n",
    "    if k >= len(data):\n",
    "        raise ValueError('k is too large')\n",
    "    #Step 1\n",
    "    C = data[nrd.choice(range(len(data)),1),]\n",
    "    #Step 2\n",
    "    Phi = Cost(C,data)\n",
    "    #for loop\n",
    "    for i in range(r):\n",
    "        prob = [l*Cost(C,x) for x in data]/Cost(C,data)\n",
    "        flag = nrd.uniform(size=len(data))\n",
    "        C = np.concatenate((C,data[prob>=flag,]))\n",
    "    #step 7\n",
    "    weights = weight(C,data)\n",
    "    #step 8: k-means++ to choose weighted points\n",
    "    c = C[nrd.choice(range(len(C)),1),]\n",
    "    while len(c) < k:\n",
    "        p = np.array([Cost(c,x) for x in C])\n",
    "        Prob = p*weights/np.sum(p*weights)\n",
    "        x = nrd.choice(range(len(C)),1,p=Prob)\n",
    "        c = np.concatenate((c,C[x,]))\n",
    "    return c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Random(k,data):\n",
    "    \"\"\"k is the number of centers, data is target data\"\"\"\n",
    "    if k >= len(data):\n",
    "        raise ValueError('k is too large')\n",
    "    return data[np.random.choice(len(data),k,replace=False),:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-means++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def kmeansplus(k,data):\n",
    "    if k >= len(data):\n",
    "        raise ValueError('k is too large')\n",
    "    #Step 1\n",
    "    C = data[nrd.choice(range(len(data)),1),]\n",
    "    #while loop\n",
    "    while len(C) < k:\n",
    "        prob = ([Cost(C,x) for x in data]/Cost(C,data)).reshape(len(data))\n",
    "        x = nrd.choice(range(len(data)),1,p=prob)\n",
    "        C = np.concatenate((C,data[x,]))\n",
    "    return C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pluspoint = kmeansplus(k,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "kmeanspar() takes exactly 4 arguments (2 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-1c2a40fa6ccf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mkmeanspar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: kmeanspar() takes exactly 4 arguments (2 given)"
     ]
    }
   ],
   "source": [
    "kmeanspar(k,2*k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.0542, -2.6631,  3.2036],\n",
       "       [-0.6991, -1.6113,  1.9838],\n",
       "       [ 1.9221, -1.4233,  0.0351],\n",
       "       [-5.0148,  2.5716,  2.2181],\n",
       "       [ 2.1317, -4.5197, -0.747 ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I use broadcasting and list comprehension without using for loop (except the largest one in the algorithm), which might be faster. However, broadcasting might cause other issues, because we can't control and know which broadcasting actually being used. For example, if each column represent one point, the codes will result in a wrong answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimation Strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The for loop might could be changed to the while loopï¼Œso that we don't need to run too many times. Or according to the paper, 15 rounds when l=0.1k, 5 rounds when l=0.5k, 2k, 10k.\n",
    "2. it seems that the k-means || algorithm is in fact slower than k-means ++, I need to figure out the reason."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Makefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%file makefile\n",
    "TARGET = center\n",
    "OBJECTS = distributions.o\n",
    "CFLAGS = -g -O3 \n",
    "LDLIBS = -lm\n",
    "CC = c99 \n",
    "\n",
    "all: $(TARGET)\n",
    "    \n",
    "clean:\n",
    "\t rm $(TARGET) $(OBJECTS)\n",
    "\n",
    "$(TARGET): $(OBJECTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading/unpacking mrjob\n",
      "  Downloading mrjob-0.4.4.tar.gz (186kB): 186kB downloaded\n",
      "  Running setup.py (path:/tmp/pip_build_bitnami/mrjob/setup.py) egg_info for package mrjob\n",
      "    \n",
      "    no previously-included directories found matching 'docs'\n",
      "    warning: no files found matching '*.sh' under directory 'bootstrap'\n",
      "Requirement already satisfied (use --upgrade to upgrade): boto>=2.2.0 in /home/bitnami/anaconda/lib/python2.7/site-packages (from mrjob)\n",
      "Downloading/unpacking filechunkio (from mrjob)\n",
      "  Downloading filechunkio-1.6.tar.gz\n",
      "  Running setup.py (path:/tmp/pip_build_bitnami/filechunkio/setup.py) egg_info for package filechunkio\n",
      "    \n",
      "Requirement already satisfied (use --upgrade to upgrade): PyYAML in /home/bitnami/anaconda/lib/python2.7/site-packages (from mrjob)\n",
      "Downloading/unpacking simplejson>=2.0.9 (from mrjob)\n",
      "  Downloading simplejson-3.6.5.tar.gz (73kB): 73kB downloaded\n",
      "  Running setup.py (path:/tmp/pip_build_bitnami/simplejson/setup.py) egg_info for package simplejson\n",
      "    \n",
      "Installing collected packages: mrjob, filechunkio, simplejson\n",
      "  Running setup.py install for mrjob\n",
      "    changing mode of build/scripts-2.7/mrjob from 664 to 775\n",
      "    \n",
      "    no previously-included directories found matching 'docs'\n",
      "    warning: no files found matching '*.sh' under directory 'bootstrap'\n",
      "    changing mode of /home/bitnami/anaconda/bin/mrjob to 775\n",
      "  Running setup.py install for filechunkio\n",
      "    \n",
      "  Running setup.py install for simplejson\n",
      "    building 'simplejson._speedups' extension\n",
      "    gcc -pthread -fno-strict-aliasing -g -O2 -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -I/home/bitnami/anaconda/include/python2.7 -c simplejson/_speedups.c -o build/temp.linux-x86_64-2.7/simplejson/_speedups.o\n",
      "    gcc -pthread -shared build/temp.linux-x86_64-2.7/simplejson/_speedups.o -L/home/bitnami/anaconda/lib -lpython2.7 -o build/lib.linux-x86_64-2.7/simplejson/_speedups.so\n",
      "    \n",
      "Successfully installed mrjob filechunkio simplejson\n",
      "Cleaning up...\n"
     ]
    }
   ],
   "source": [
    "!pip install mrjob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
