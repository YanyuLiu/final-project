{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skalable K-means++"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The paper I used is skalable K-means, which introduce a parallelizable initialization algorithm, k-means||.\n",
    "\n",
    "K-means is a popular method to separate data into k groups to achieve the minimum distance between each point and its cluster center. Two major theoretic downsides of K-means are that the final result can be very bad compared to the global optimal and in the worst case running time can be exponential. K-means++ is designed to \n",
    "\n",
    "therefore, the initial k points are critical for obtaining a good final result.\n",
    "\n",
    "K-means ++, an algorithm to choose the initial values of k-means clustering, has been proved that the initial values generated by this algorithm is close to global optimum. It is guaranteed to find a solution that is O(log k) competitive to the optimal k-means solution. However, it's not suitable for massive data, as we need to pass k times over the whole data set.\n",
    "\n",
    "Therefore, the author come up with a updated initialization algorithm, k-means||, to address this problem, which only needs logarithmic number of passes. This really interests me, because k-means clustering is really widely used in the data analysis. It's meaningful to figure out how to apply this to large-scale data sets which are increasingly prevalent. Besides, the algorithm is parallelizable, so that I can explore more and learn more about parallelization in python programming."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm (Pseudocode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### k-means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let X={$x_1,x_2,...x_n$} be the set of points in d-dimensional Euclidean space, and k is the number of clusters we will divide X into. This starts with randomly choosing k points from X as initial values of centers $c_1,...,c_k$. In each iteration, each point $x_i$ is assigned to the closest cluster by calculating $\\text{arg min}_j d(x_i,c_j)$. The calculate the new centroids of the observations in the new clusters as the k centers for the next iteration.\n",
    "$$centroid(X) = \\frac{1}{|X|}\\sum_{x \\in X} x$$\n",
    "The iteration is repeated until a stable set of centers is obtained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### k-means++"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main idea of k-means++ is to choose centers one by one in a controlled fashion, where the current set of chosen centers will influence the choice of next center. The algorithm is shown as below:\n",
    "1. C <- sample a point uniformly at random from X\n",
    "2. while |C|<k, do:\n",
    "3. $\\qquad$ sample x $\\in$ X with probability $\\frac{d^2(x,c)}{\\phi_x(c)}$, where\n",
    "$$\\phi_Y(C) = \\sum_{y\\in Y}d^2(y,C)$$\n",
    "4. $\\qquad$ C <- C $\\cup$ {x}\n",
    "5. end while"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### k-means ||"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. C <- smaple a point uniformly at random from X\n",
    "2. $\\psi$ <- $\\phi(C)$\n",
    "3. for O($\\log \\phi$) times do:\n",
    "4. $\\qquad$ C' <- sample each point x $\\in$ X independently with probability $p_x =\\frac{l \\cdot d^2(x,c)}{\\phi_x(c)}$ \n",
    "5. $\\qquad$ C <- C $\\cup$ C'\n",
    "5. end for\n",
    "7. For x $\\in$ C, set $w_x$ to be the number of points in X closer to x than any other point in C\n",
    "8. Recluster the weighted points in C into K clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random means get k initual points randomly, each points in the data has the same probability to be chosen. We can use random.choice to get that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advantages and Disadvantages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
