{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy.random as nrd\n",
    "%matplotlib inline\n",
    "%precision 4\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GAUSSMIXTURE, which is synthetic. To generate it, I first sample k=(3,4,5) centers from a 3-dimensional Gaussian distribution with mean 0 and variance 5$I_3$. Then add points from Gaussian distributions of unit variance around centers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#first only generate k=5\n",
    "\n",
    "nrd.seed(1234)\n",
    "k = 5\n",
    "centers = nrd.multivariate_normal([0,0,0],5*np.identity(3),k)\n",
    "data = [nrd.multivariate_normal(center, np.identity(3),100) for center in centers]\n",
    "data = np.vstack(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%%file kmeans.py\n",
    "\n",
    "#centroid\n",
    "# def Centroid(Y):\n",
    "#     \"\"\"Y is a subset of the dataset\"\"\"\n",
    "#     return np.average(Y,axis=0)\n",
    "\n",
    "#cost\n",
    "def Cost(C, Y):\n",
    "    \"\"\"C is a subset of the dataset, Y can be a point or a subset\"\"\"\n",
    "    if  len(Y.shape)==1 or Y.shape[0]==1:\n",
    "        MinIndex = np.argmin(np.sum((Y-C)**2,axis=1))\n",
    "        return np.sum((Y-C[MinIndex,])**2)\n",
    "    else:\n",
    "        return np.sum([Cost(C,Y_i) for Y_i in Y])\n",
    "    \n",
    "def weight(C, data):\n",
    "    \"\"\"C is the centroid set and data is the data set\"\"\"\n",
    "    Cost_matrix = np.array([np.sum((c-x)**2) for c in C\n",
    "                                             for x in data]).reshape(len(C),len(data))\n",
    "    Index_min = list(np.argmin(Cost_matrix,axis=0))\n",
    "    return np.array([Index_min.count(i) for i in range(len(C))])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-means||"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def kmeanspar(k,l):\n",
    "    #Step 1\n",
    "    C = data[nrd.choice(range(len(data)),1),]\n",
    "    #Step 2\n",
    "    Phi = Cost(C,data)\n",
    "    #for loop\n",
    "    for i in range(int(np.log(Phi))):\n",
    "        prob = [l*Cost(C,x) for x in data]/Cost(C,data)\n",
    "        flag = nrd.uniform(size=len(data))\n",
    "        C = np.concatenate((C,data[prob>=flag,]))\n",
    "    #step 7\n",
    "    weights = weight(C,data)\n",
    "    #step 8: k-means++ to choose weighted points\n",
    "    c = C[nrd.choice(range(len(C)),1),]\n",
    "    while len(c) < k:\n",
    "        p = np.array([Cost(c,x) for x in C])\n",
    "        Prob = p*weights/np.sum(p*weights)\n",
    "        x = nrd.choice(range(len(C)),1,p=Prob)\n",
    "        c = np.concatenate((c,C[x,]))\n",
    "    return c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random means get k initual points randomly, each points in the data has the same probability to be chosen. We can use random.choice to get that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-means++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def kmeansplus(k,data):\n",
    "    #Step 1\n",
    "    C = data[nrd.choice(range(len(data)),1),]\n",
    "    #while loop\n",
    "    while len(C) < k:\n",
    "        prob = ([Cost(C,x) for x in data]/Cost(C,data)).reshape(len(data))\n",
    "        x = nrd.choice(range(len(data)),1,p=prob)\n",
    "        C = np.concatenate((C,data[x,]))\n",
    "    return C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.1336, -1.4892, -1.3834],\n",
       "       [-4.3293,  2.9194,  1.3839],\n",
       "       [ 3.692 , -4.4052,  3.1092],\n",
       "       [ 0.7094, -2.1348,  2.1346],\n",
       "       [ 2.401 , -6.3684, -1.4968]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pluspoint = kmeansplus(k,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.692 , -4.4052,  3.1092],\n",
       "       [-1.1236, -0.4924,  3.5533],\n",
       "       [ 1.2785, -3.3992, -0.6267],\n",
       "       [ 0.5748, -2.9621,  3.8977],\n",
       "       [-5.9876,  1.8227,  2.9829]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeanspar(k,2*k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.0542, -2.6631,  3.2036],\n",
       "       [-0.6991, -1.6113,  1.9838],\n",
       "       [ 1.9221, -1.4233,  0.0351],\n",
       "       [-5.0148,  2.5716,  2.2181],\n",
       "       [ 2.1317, -4.5197, -0.747 ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I use broadcasting and list comprehension without using for loop (except the largest one in the algorithm), which might be faster. However, broadcasting might cause other issues, because we can't control and know which broadcasting actually being used. For example, if each column represent one point, the codes will result in a wrong answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimation Strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The for loop might could be changed to the while loopï¼Œso that we don't need to run too many times. Or according to the paper, 15 rounds when l=0.1k, 5 rounds when l=0.5k, 2k, 10k.\n",
    "2. it seems that the k-means || algorithm is in fact slower than k-means ++, I need to figure out the reason."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Makefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%file makefile\n",
    "TARGET = center\n",
    "OBJECTS = distributions.o\n",
    "CFLAGS = -g -O3 \n",
    "LDLIBS = -lm\n",
    "CC = c99 \n",
    "\n",
    "all: $(TARGET)\n",
    "    \n",
    "clean:\n",
    "\t rm $(TARGET) $(OBJECTS)\n",
    "\n",
    "$(TARGET): $(OBJECTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
