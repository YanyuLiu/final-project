{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy.random as nrd\n",
    "from sklearn.cluster import KMeans\n",
    "from kmeans import *\n",
    "import timeit\n",
    "%matplotlib inline\n",
    "%precision 4\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GAUSSMIXTURE, which is synthetic. To generate it, I first sample k=(3,4,5) centers from a 3-dimensional Gaussian distribution with mean 0 and variance 5$I_3$. Then add points from Gaussian distributions of unit variance around centers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def GAUSSMIXTURE(k,R):\n",
    "    \"\"\"R is the variance to generate centers, K is the number of centers\n",
    "    will sample 10000 points in 10-dimensional space\"\"\"\n",
    "    n = 10000\n",
    "    centers = nrd.multivariate_normal([0]*10,R*np.identity(10),k)\n",
    "    data = [nrd.multivariate_normal(center, np.identity(10),int(n/k)) for center in centers]\n",
    "    data = np.vstack(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = GAUSSMIXTURE(50,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def Cost(C, Y):\n",
    "    \"\"\"C is a subset of the dataset, Y can be a point or a subset\"\"\"\n",
    "    if  len(Y.shape)==1 or Y.shape[0]==1:\n",
    "        #Y is a point\n",
    "        MinIndex = np.argmin(np.sum((Y-C)**2,axis=1))\n",
    "        return np.sum((Y-C[MinIndex,])**2)\n",
    "    else:\n",
    "        return np.sum([Cost(C,Y_i) for Y_i in Y])\n",
    "\n",
    "def weight(C, data):\n",
    "    \"\"\"C is the centroid set and data is the target data set\"\"\"\n",
    "    if len(C.shape)==1 or C.shape[0]==1:\n",
    "        #C only have one point\n",
    "        if len(data.shape)==1 or data.shape[0]==1:\n",
    "            return np.array([1])\n",
    "        else:\n",
    "            return np.array([len(data)])\n",
    "    else:\n",
    "        Index_min = [np.argmin(np.sum((x-C)**2,axis=1)) for x in data]\n",
    "        return np.array([Index_min.count(i) for i in range(len(C))]).astype(float)\n",
    "\n",
    "def weight_v1(C, data):\n",
    "    \"\"\"C is the centroid set and data is the target data set\"\"\"\n",
    "    if len(C.shape)==1 or C.shape[0]==1:\n",
    "        #C only have one point\n",
    "        if len(data.shape)==1 or data.shape[0]==1:\n",
    "            return np.array([1])\n",
    "        else:\n",
    "            return np.array([len(data)])\n",
    "    else:\n",
    "        Cost_matrix = np.array([np.sum((c-x)**2) for c in C\n",
    "                                             for x in data]).reshape(len(C),len(data))\n",
    "        Index_min = list(np.argmin(Cost_matrix,axis=0))\n",
    "        return np.array([Index_min.count(i) for i in range(len(C))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-means||"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def kmeanspar(k,l,r,data):\n",
    "    \"\"\"k is the number of centers, l is the expected number of intermediate points\n",
    "    in each iteration, r is the number of iterations, data is the target data set\"\"\"\n",
    "    #l*r should be larger than k in case k-means|| select too few points\n",
    "    if l*r < k:\n",
    "        raise ValueError('r or l must be bigger, ')\n",
    "    #if k is too large\n",
    "    if k >= len(data):\n",
    "        raise ValueError('k is too large')\n",
    "    #Step 1\n",
    "    C = data[nrd.choice(range(len(data)),1),]\n",
    "    #for loop\n",
    "    for i in range(r):\n",
    "        prob = [l*Cost(C,x) for x in data]/Cost(C,data)\n",
    "        flag = nrd.uniform(size=len(data))\n",
    "        C = np.concatenate((C,data[prob>=flag,]))\n",
    "    #step 7\n",
    "    weights = weight(C,data)\n",
    "    #step 8: k-means++ to choose weighted points\n",
    "    c = C[nrd.choice(range(len(C)),1),]\n",
    "    while len(c) < k:\n",
    "        p = np.array([Cost(c,x) for x in C])\n",
    "        Prob = p*weights/np.sum(p*weights)\n",
    "        x = nrd.choice(range(len(C)),1,p=Prob)\n",
    "        c = np.concatenate((c,C[x,]))\n",
    "    ##carry out K-means clustering\n",
    "    km = KMeans(n_clusters=k,init=c,n_init=1)\n",
    "    km.fit(data)\n",
    "    return km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "km = kmeanspar(50,50/2,5,data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Random(k,data):\n",
    "    \"\"\"k is the number of centers, data is target data\"\"\"\n",
    "    if k >= len(data):\n",
    "        raise ValueError('k is too large')\n",
    "    ##carry out K-means clustering\n",
    "    km = KMeans(n_clusters=k,init='random')\n",
    "    km.fit(data)\n",
    "    return km"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-means++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def kmeansplus(k,data):\n",
    "    if k >= len(data):\n",
    "        raise ValueError('k is too large')\n",
    "    km = KMeans(n_clusters=k,init='k-means++')\n",
    "    km.fit(data)\n",
    "    return km"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clustering_cost(data,initial):\n",
    "    \"\"\"K is \n",
    "    initial is the initialization way, could be Random, kmeanspar or kmeansplus\"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k = 50; R = 10;\n",
    "l = 0.5*k; r = 5;\n",
    "data = GAUSSMIXTURE(k,R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loops, best of 3: 7.07 s per loop\n",
      "1 loops, best of 3: 658 ms per loop\n",
      "1 loops, best of 3: 475 ms per loop\n"
     ]
    }
   ],
   "source": [
    "#carry out K-means clustering and time profiling\n",
    "#try different l and r\n",
    "%timeit kmeanspar(k,l,r,data)\n",
    "%timeit kmeansplus(k,data)\n",
    "%timeit Random(k,data)\n",
    "    \n",
    "# km_1 = KMeans(n_clusters=k,init='k-means++')\n",
    "# km_2 = KMeans(n_clusters=k,init='random')\n",
    "# km_3 = KMeans(n_clusters=k,init=c1)\n",
    "\n",
    "# %timeit Random(data)\n",
    "# %timeit km_2.fit(data)\n",
    "# %timeit km_3.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          3235683 function calls (3205683 primitive calls) in 8.447 seconds\n",
      "\n",
      "   Ordered by: internal time\n",
      "   List reduced from 73 to 10 due to restriction <10>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "   747421    2.847    0.000    2.847    0.000 {method 'reduce' of 'numpy.ufunc' objects}\n",
      "        1    2.441    2.441    6.304    6.304 kmeans.py:18(weight)\n",
      "   747305    0.989    0.000    4.697    0.000 fromnumeric.py:1623(sum)\n",
      "61131/31131    0.945    0.000    2.043    0.000 kmeans.py:9(Cost)\n",
      "   747449    0.537    0.000    0.537    0.000 {isinstance}\n",
      "   747366    0.326    0.000    3.172    0.000 _methods.py:31(_sum)\n",
      "    61126    0.108    0.000    0.108    0.000 {method 'argmin' of 'numpy.ndarray' objects}\n",
      "      200    0.057    0.000    0.057    0.000 {numpy.core.multiarray.array}\n",
      "        1    0.055    0.055    8.447    8.447 <ipython-input-25-c34800b429f1>:1(kmeanspar)\n",
      "    61126    0.047    0.000    0.155    0.000 fromnumeric.py:938(argmin)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stats = %prun -r -q kmeanspar(k,l,r,data)\n",
    "stats.sort_stats('time').print_stats(10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          72581 function calls in 0.695 seconds\n",
      "\n",
      "   Ordered by: internal time\n",
      "   List reduced from 66 to 10 due to restriction <10>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "      618    0.178    0.000    0.420    0.001 pairwise.py:143(euclidean_distances)\n",
      "      118    0.154    0.001    0.360    0.003 k_means_.py:400(_labels_inertia_precompute_dense)\n",
      "      736    0.118    0.000    0.118    0.000 {numpy.core._dotblas.dot}\n",
      "     5673    0.078    0.000    0.078    0.000 {method 'reduce' of 'numpy.ufunc' objects}\n",
      "       10    0.048    0.005    0.307    0.031 k_means_.py:41(_k_init)\n",
      "      118    0.018    0.000    0.018    0.000 _k_means.pyx:244(_centers_dense)\n",
      "     3091    0.015    0.000    0.078    0.000 validation.py:37(_assert_all_finite)\n",
      "      490    0.009    0.000    0.009    0.000 {method 'cumsum' of 'numpy.ndarray' objects}\n",
      "     8159    0.009    0.000    0.009    0.000 {numpy.core.multiarray.array}\n",
      "     1855    0.007    0.000    0.013    0.000 shape_base.py:60(atleast_2d)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stats = %prun -r -q kmeansplus(k,data)\n",
    "stats.sort_stats('time').print_stats(10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          3050990 function calls (3020990 primitive calls) in 7.966 seconds\n",
      "\n",
      "   Ordered by: internal time\n",
      "   List reduced from 72 to 10 due to restriction <10>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "   701569    2.734    0.000    2.734    0.000 {method 'reduce' of 'numpy.ufunc' objects}\n",
      "        1    2.311    2.311    7.966    7.966 <ipython-input-33-58047ee5deba>:15(kmeanspar)\n",
      "   701423    0.913    0.000    4.432    0.000 fromnumeric.py:1623(sum)\n",
      "60690/30690    0.913    0.000    1.976    0.000 kmeans.py:9(Cost)\n",
      "   701627    0.490    0.000    0.490    0.000 {isinstance}\n",
      "   701514    0.297    0.000    3.031    0.000 _methods.py:31(_sum)\n",
      "    60685    0.105    0.000    0.105    0.000 {method 'argmin' of 'numpy.ndarray' objects}\n",
      "      270    0.053    0.000    0.053    0.000 {numpy.core.multiarray.array}\n",
      "    60685    0.048    0.000    0.152    0.000 fromnumeric.py:938(argmin)\n",
      "      116    0.042    0.000    0.042    0.000 {method 'count' of 'list' objects}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stats = %prun -r -q kmeanspar(k,l,r,data)\n",
    "stats.sort_stats('time').print_stats(10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I use broadcasting and list comprehension without using for loop (except the largest one in the algorithm), which might be faster. However, broadcasting might cause other issues, because we can't control and know which broadcasting actually being used. For example, if each column represent one point, the codes will result in a wrong answer.\n",
    "2. When do the parallelization, found that the weight function use lots of time. Because there is a two for loop inside. Change it to one for loop, 2.7 -> 0.295097827911. Also change the original one\n",
    "3. there is a trick that we can use, don't use cost(data,C), just normalize them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimation Strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The for loop might could be changed to the while loop，so that we don't need to run too many times. Or according to the paper, 15 rounds when l=0.1k, 5 rounds when l=0.5k, 2k, 10k.\n",
    "2. k-means || algorithm is in fact far slower than k-means ++, I need to use Cython to improve the speed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "CompileError",
     "evalue": "command 'gcc' failed with exit status 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCompileError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-185-92024bbfb56b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mu'cython'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mu'-a '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mu'#%%file kmeanspar.pyx\\n\\nimport numpy as np\\ncimport numpy as np\\ncimport cython\\nfrom libc.stdlib cimport rand\\ncdef extern from \"stdlib.h\":\\n    int RAND_MAX\\n    \\ndef randnum():\\n    return rand()/float(RAND_MAX)\\n\\n\\ndef distance(double[::1] p1,double[::1] p2):\\n    cdef int i, d\\n    cdef double w=0\\n    d = p1.shape[0]\\n    for i in range(d):\\n        w += (p1[i]-p2[i])**2\\n    return w\\n\\n# def min_distance_C(double p1,double[::1] C):\\n#     cdef int i, n\\n#     cdef double dmin\\n#     n = C.shape[0]\\n#     dmin = distance(p1,C[0,])\\n#     for i in range(n):\\n#         dmin\\n#     distance()\\n    \\n    \\ndef Cost_C(double[:,::1] C,double[:,::1] Y):\\n    cdef int i, j, n_C, n_Y, d\\n    cdef double cost = 0\\n    n_C = C.shape[0]\\n    cdef double[::1] dists=np.zeros(n_C)\\n    d = C.shape[1]\\n    n_Y = Y.shape[0]\\n    for i in range(n_Y):\\n        for j in range(n_C):\\n            dists[j] = distance(Y[i,:],C[j,:])\\n        cost += np.sum(dists)\\n    return cost\\n\\n# #def weight_C():\\n    \\n    \\ndef kmeanspar_C(int k,int l,int r,double[:,::1] data):\\n    cdef int n_Y, i, j, d\\n    d = data.shape[1]\\n    n_Y = data.shape[0]\\n    cdef double[::1] prob=np.zeros(n_Y)\\n    cdef double[::1] flag=np.zeros(n_Y)\\n    C = data[np.random.choice(range(n_Y),1),:]\\n    k = k+1\\n    for i in range(r):\\n        for j in range(n_Y):\\n            flag[j] = randnum()\\n            prob[j] = Cost_C(C,data[j,:])\\n        prob = prob/sum(prob)*float(l)\\n        C = np.concatenate((C,data[prob>=flag,:]))\\n            \\n\\n    \\n# def kmeanspar_C(int k,int l,int r,double[:,:] data):\\n#     #Step 1\\n#     C = data[np.random.choice(range(len(data)),1),]\\n#     #for loop\\n#     for i in range(r):\\n#         prob = [l*Cost(C,x) for x in data]/Cost(C,data)\\n#         flag = nrd.uniform(size=len(data))\\n#         C = np.concatenate((C,data[prob>=flag,]))\\n#     #step 7\\n#     Cost_matrix = np.array([np.sum((c-x)**2) for c in C\\n#                                              for x in data]).reshape(len(C),len(data))\\n#     Index_min = list(np.argmin(Cost_matrix,axis=0))\\n#     weights = np.array([Index_min.count(i) for i in range(len(C))])\\n#     #step 8: k-means++ to choose weighted points\\n#     c = C[nrd.choice(range(len(C)),1),]\\n#     while len(c) < k:\\n#         p = np.array([Cost(c,x) for x in C])\\n#         Prob = p*weights/np.sum(p*weights)\\n#         x = nrd.choice(range(len(C)),1,p=Prob)\\n#         c = np.concatenate((c,C[x,]))\\n#     ##carry out K-means clustering\\n#     km = KMeans(n_clusters=k,init=c)\\n#     km.fit(data)\\n#     return km   '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/bitnami/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[1;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[0;32m   2262\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2263\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2264\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2265\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2266\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/bitnami/anaconda/lib/python2.7/site-packages/Cython/Build/IpythonMagic.pyc\u001b[0m in \u001b[0;36mcython\u001b[1;34m(self, line, cell)\u001b[0m\n",
      "\u001b[1;32m/home/bitnami/anaconda/lib/python2.7/site-packages/IPython/core/magic.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, *a, **k)\u001b[0m\n\u001b[0;32m    191\u001b[0m     \u001b[1;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m         \u001b[0mcall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/bitnami/anaconda/lib/python2.7/site-packages/Cython/Build/IpythonMagic.pyc\u001b[0m in \u001b[0;36mcython\u001b[1;34m(self, line, cell)\u001b[0m\n\u001b[0;32m    272\u001b[0m             \u001b[0mbuild_extension\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_temp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpyx_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m             \u001b[0mbuild_extension\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_lib\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mlib_dir\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 274\u001b[1;33m             \u001b[0mbuild_extension\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    275\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_code_cache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/bitnami/anaconda/lib/python2.7/distutils/command/build_ext.pyc\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    335\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    336\u001b[0m         \u001b[1;31m# Now actually compile and link everything.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 337\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_extensions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    338\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcheck_extensions_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/bitnami/anaconda/lib/python2.7/distutils/command/build_ext.pyc\u001b[0m in \u001b[0;36mbuild_extensions\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mext\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextensions\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 446\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_extension\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    447\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mbuild_extension\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/bitnami/anaconda/lib/python2.7/distutils/command/build_ext.pyc\u001b[0m in \u001b[0;36mbuild_extension\u001b[1;34m(self, ext)\u001b[0m\n\u001b[0;32m    494\u001b[0m                                          \u001b[0mdebug\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m                                          \u001b[0mextra_postargs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mextra_args\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 496\u001b[1;33m                                          depends=ext.depends)\n\u001b[0m\u001b[0;32m    497\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m         \u001b[1;31m# XXX -- this is a Vile HACK!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/bitnami/anaconda/lib/python2.7/distutils/ccompiler.pyc\u001b[0m in \u001b[0;36mcompile\u001b[1;34m(self, sources, output_dir, macros, include_dirs, debug, extra_preargs, extra_postargs, depends)\u001b[0m\n\u001b[0;32m    572\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    573\u001b[0m                 \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 574\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextra_postargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpp_opts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    575\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    576\u001b[0m         \u001b[1;31m# Return *all* object filenames, not just the ones we just built.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/bitnami/anaconda/lib/python2.7/distutils/unixccompiler.pyc\u001b[0m in \u001b[0;36m_compile\u001b[1;34m(self, obj, src, ext, cc_args, extra_postargs, pp_opts)\u001b[0m\n\u001b[0;32m    120\u001b[0m                        extra_postargs)\n\u001b[0;32m    121\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mDistutilsExecError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 122\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mCompileError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m     def create_static_lib(self, objects, output_libname,\n",
      "\u001b[1;31mCompileError\u001b[0m: command 'gcc' failed with exit status 1"
     ]
    }
   ],
   "source": [
    "%%cython -a \n",
    "#%%file kmeanspar.pyx\n",
    "\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "cimport cython\n",
    "from libc.stdlib cimport rand\n",
    "cdef extern from \"stdlib.h\":\n",
    "    int RAND_MAX\n",
    "    \n",
    "def randnum():\n",
    "    return rand()/float(RAND_MAX)\n",
    "\n",
    "\n",
    "def distance(double[::1] p1,double[::1] p2):\n",
    "    cdef int i, d\n",
    "    cdef double w=0\n",
    "    d = p1.shape[0]\n",
    "    for i in range(d):\n",
    "        w += (p1[i]-p2[i])**2\n",
    "    return w\n",
    "\n",
    "# def min_distance_C(double p1,double[::1] C):\n",
    "#     cdef int i, n\n",
    "#     cdef double dmin\n",
    "#     n = C.shape[0]\n",
    "#     dmin = distance(p1,C[0,])\n",
    "#     for i in range(n):\n",
    "#         dmin\n",
    "#     distance()\n",
    "    \n",
    "    \n",
    "def Cost_C(double[:,::1] C,double[:,::1] Y):\n",
    "    cdef int i, j, n_C, n_Y, d\n",
    "    cdef double cost = 0\n",
    "    n_C = C.shape[0]\n",
    "    cdef double[::1] dists=np.zeros(n_C)\n",
    "    d = C.shape[1]\n",
    "    n_Y = Y.shape[0]\n",
    "    for i in range(n_Y):\n",
    "        for j in range(n_C):\n",
    "            dists[j] = distance(Y[i,:],C[j,:])\n",
    "        cost += np.sum(dists)\n",
    "    return cost\n",
    "\n",
    "# #def weight_C():\n",
    "    \n",
    "    \n",
    "def kmeanspar_C(int k,int l,int r,double[:,::1] data):\n",
    "    cdef int n_Y, i, j, d\n",
    "    d = data.shape[1]\n",
    "    n_Y = data.shape[0]\n",
    "    cdef double[::1] prob=np.zeros(n_Y)\n",
    "    cdef double[::1] flag=np.zeros(n_Y)\n",
    "    cdef double sum\n",
    "    C = data[np.random.choice(range(n_Y),1),:]\n",
    "    k = k+1\n",
    "    for i in range(r):\n",
    "        for j in range(n_Y):\n",
    "            flag[j] = randnum()\n",
    "            prob[j] = Cost_C(C,data[j,:])\n",
    "        prob = prob/sum(prob)*float(l)\n",
    "        C = np.concatenate((C,data[prob>=flag,:]))\n",
    "            \n",
    "\n",
    "    \n",
    "# def kmeanspar_C(int k,int l,int r,double[:,:] data):\n",
    "#     #Step 1\n",
    "#     C = data[np.random.choice(range(len(data)),1),]\n",
    "#     #for loop\n",
    "#     for i in range(r):\n",
    "#         prob = [l*Cost(C,x) for x in data]/Cost(C,data)\n",
    "#         flag = nrd.uniform(size=len(data))\n",
    "#         C = np.concatenate((C,data[prob>=flag,]))\n",
    "#     #step 7\n",
    "#     Cost_matrix = np.array([np.sum((c-x)**2) for c in C\n",
    "#                                              for x in data]).reshape(len(C),len(data))\n",
    "#     Index_min = list(np.argmin(Cost_matrix,axis=0))\n",
    "#     weights = np.array([Index_min.count(i) for i in range(len(C))])\n",
    "#     #step 8: k-means++ to choose weighted points\n",
    "#     c = C[nrd.choice(range(len(C)),1),]\n",
    "#     while len(c) < k:\n",
    "#         p = np.array([Cost(c,x) for x in C])\n",
    "#         Prob = p*weights/np.sum(p*weights)\n",
    "#         x = nrd.choice(range(len(C)),1,p=Prob)\n",
    "#         c = np.concatenate((c,C[x,]))\n",
    "#     ##carry out K-means clustering\n",
    "#     km = KMeans(n_clusters=k,init=c)\n",
    "#     km.fit(data)\n",
    "#     return km   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1592"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randnum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting setup.py\n"
     ]
    }
   ],
   "source": [
    "%%file setup.py\n",
    "from distutils.core import setup, Extension\n",
    "from Cython.Build import cythonize\n",
    "\n",
    "ext = Extension(\"KmeansparC\",\n",
    "              sources=[\"kmeanspar.\"])\n",
    "\n",
    "setup(name = \"cython_kmeanspar\",\n",
    "      ext_modules = cythonize(ext))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! python setup.py build_ext -i &> /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named KmeansparC",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-143-4fa529c93e5a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mKmeansparC\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m: No module named KmeansparC"
     ]
    }
   ],
   "source": [
    "import KmeansparC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###parallelization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from multiprocessing import Pool, cpu_count\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def min_distance(p1, C, axis = 1):\n",
    "    return np.min(np.sum((p1-C)**2,axis))\n",
    "\n",
    "def argmin_distance(p1, C, axis = 1):\n",
    "    return np.argmin(np.sum((p1-C)**2,axis))\n",
    "\n",
    "def Cost_par(C, Y):\n",
    "    \"\"\"C is a subset of the dataset, Y can be a point or a subset\"\"\"\n",
    "    pool = Pool(processes=cpu_count())\n",
    "    PartialMinDist = partial(min_distance, C=C, axis=1)\n",
    "    cost = np.sum(pool.map(PartialMinDist, Y))\n",
    "    pool.close()\n",
    "    pool.terminate()\n",
    "    return cost\n",
    "\n",
    "def weight_par(C, data):\n",
    "    start = timeit.default_timer()\n",
    "    pool = Pool(processes=cpu_count())\n",
    "    PartialArgminDist = partial(argmin_distance, C=C, axis=1)\n",
    "    Index_min = list(pool.map(PartialArgminDist,data))\n",
    "    return np.array([Index_min.count(i) for i in range(len(C))])\n",
    "    \n",
    "def kmeanspar_par(k,l,r,data):\n",
    "    \"\"\"k is the number of centers, l is the expected number of intermediate points\n",
    "    in each iteration, r is the number of iterations, data is the target data set\"\"\"\n",
    "    #l*r should be larger than k in case k-means|| select too few points\n",
    "    if l*r < k:\n",
    "        raise ValueError('r or l must be bigger, ')\n",
    "    #if k is too large\n",
    "    if k >= len(data):\n",
    "        raise ValueError('k is too large')\n",
    "        \n",
    "    #Step 1\n",
    "    C = data[nrd.choice(range(len(data)),1),]\n",
    "    #for loop\n",
    "    for i in range(r):\n",
    "        pool = Pool(processes=cpu_count())\n",
    "        PartialMinDist = partial(min_distance, C=C, axis=1)\n",
    "        prob = np.array(pool.map(PartialMinDist, data))\n",
    "        prob = prob/np.sum(prob)*float(l)\n",
    "        pool.close()\n",
    "        pool.terminate()\n",
    "        flag = nrd.uniform(size=len(data))\n",
    "        C = np.concatenate((C,data[prob>=flag,]))\n",
    "    #step 7\n",
    "    weights = weight_par(C,data)\n",
    "    #step 8: k-means++ to choose weighted points\n",
    "    c = C[nrd.choice(range(len(C)),1),]\n",
    "    while len(c) < k:\n",
    "        p = np.array([Cost(c,x) for x in C])\n",
    "        Prob = p*weights/np.sum(p*weights)\n",
    "        x = nrd.choice(range(len(C)),1,p=Prob)\n",
    "        c = np.concatenate((c,C[x,]))\n",
    "    ##carry out K-means clustering\n",
    "    km = KMeans(n_clusters=k,init=c)\n",
    "    km.fit(data)\n",
    "    return km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loops, best of 3: 1.81 s per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit kmeanspar_par(k,l,r,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpu_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Makefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%file makefile\n",
    "TARGET = center\n",
    "OBJECTS = distributions.o\n",
    "CFLAGS = -g -O3 \n",
    "LDLIBS = -lm\n",
    "CC = c99 \n",
    "\n",
    "all: $(TARGET)\n",
    "    \n",
    "clean:\n",
    "\t rm $(TARGET) $(OBJECTS)\n",
    "\n",
    "$(TARGET): $(OBJECTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Application Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Application to simulated/real problem and comparative anlaysis (up to 40 points)\n",
    "As an example, a 40-point answer could include an extensive comparative analysis against the majority of classes of existing algorithms used to solve a problem with benchmarking and a thoguhtful consideration of the benefits/drawbacks of each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
