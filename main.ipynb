{
 "metadata": {
  "name": "",
  "signature": "sha256:e39ddec17a31affb8b93e00a74fff3a389bf8268eb4157d6e5d6abae61b8c98f"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import division\n",
      "import os\n",
      "import sys\n",
      "import glob\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "%matplotlib inline\n",
      "%precision 4\n",
      "plt.style.use('ggplot')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Dataset"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "GAUSSMIXTURE, which is synthetic. To generate it, I first sample k=(3,4,5) centers from a 3-dimensional Gaussian distribution with mean 0 and variance 5$I_3$. Then add points from Gaussian distributions of unit variance around centers."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#first only generate k=5\n",
      "import numpy.random as nrd\n",
      "nrd.seed(1234)\n",
      "k = 5\n",
      "centers = nrd.multivariate_normal([0,0,0],5*np.identity(3),k)\n",
      "data = [nrd.multivariate_normal(center, np.identity(3),100) for center in centers]\n",
      "data = np.vstack(data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#%%file kmeans.py\n",
      "\n",
      "#centroid\n",
      "# def Centroid(Y):\n",
      "#     \"\"\"Y is a subset of the dataset\"\"\"\n",
      "#     return np.average(Y,axis=0)\n",
      "\n",
      "#cost\n",
      "def Cost(C, Y):\n",
      "    \"\"\"C is a subset of the dataset, Y can be a point or a subset\"\"\"\n",
      "    if  len(Y.shape)==1 or Y.shape[0]==1:\n",
      "        MinIndex = np.argmin(np.sum((Y-C)**2,axis=1))\n",
      "        return np.sum((Y-C[MinIndex,])**2)\n",
      "    else:\n",
      "        return np.sum([Cost(C,Y_i) for Y_i in Y])\n",
      "    \n",
      "from collections import Counter\n",
      "def weight(C, data):\n",
      "    \"\"\"C is the centroid set and data is the data set\"\"\"\n",
      "    Cost_matrix = np.array([np.sum((c-x)**2) for c in C\n",
      "                                             for x in data]).reshape(len(C),len(data))\n",
      "    Index_min = np.argmin(Cost_matrix,axis=0)\n",
      "    return Counter(Index_min)\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Important functions"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "k-means||"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def kmeanspar(k,l):\n",
      "    #Step 1\n",
      "    C = data[nrd.choice(range(len(data)),1),]\n",
      "    #Step 2\n",
      "    Phi = Cost(C,data)\n",
      "    #for loop\n",
      "    for i in range(int(np.log(Phi))):\n",
      "        prob = [l*Cost(C,x) for x in data]/Cost(C,data)\n",
      "        flag = nrd.uniform(size=len(data))\n",
      "        C = np.concatenate(C,data[prob>=flag,])\n",
      "    #step 7\n",
      "    weights = weight(C,data)\n",
      "    \n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Random"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Random means get k initual points randomly, each points in the data has the same probability to be chosen. We can use random.choice to get that."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "K-means++"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def kmeansplus(k,data):\n",
      "    #Step 1\n",
      "    C = data[nrd.choice(range(len(data)),1),]\n",
      "    while len(C) < k:\n",
      "        \n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Profile"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "I use broadcasting and list comprehension without using for loop (except the largest one in the algorithm), which might be faster. However, broadcasting might cause other issues, because we can't control and know which broadcasting actually being used. For example, if each column represent one point, the codes will result in a wrong answer."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Optimation Strategies"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "1. The for loop might could be changed to the while loop\uff0cso that we don't need to run too many times. Or according to the paper, 15 rounds when l=0.1k, 5 rounds when l=0.5k, 2k, 10k.\n",
      "2. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}